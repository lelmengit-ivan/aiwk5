{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca735f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a0f9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_explore_data(file_path):\n",
    "    \"\"\"\n",
    "    Load healthcare data and perform initial exploration\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the data file\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Loaded data\n",
    "    \"\"\"\n",
    "    print(\"üìä Loading and Exploring Hospital Readmission Data\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"‚úÖ Data loaded successfully: {data.shape[0]} rows, {data.shape[1]} columns\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Basic information\n",
    "    print(\"\\nüìà Dataset Overview:\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "    print(f\"Memory usage: {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Data types\n",
    "    print(\"\\nüîß Data Types:\")\n",
    "    print(data.dtypes.value_counts())\n",
    "    \n",
    "    # Missing values analysis\n",
    "    print(\"\\n‚ùì Missing Values Analysis:\")\n",
    "    missing_info = pd.DataFrame({\n",
    "        'Missing Count': data.isnull().sum(),\n",
    "        'Missing Percentage': (data.isnull().sum() / len(data)) * 100\n",
    "    }).sort_values('Missing Count', ascending=False)\n",
    "    \n",
    "    # Display columns with missing values\n",
    "    missing_columns = missing_info[missing_info['Missing Count'] > 0]\n",
    "    if len(missing_columns) > 0:\n",
    "        print(f\"Columns with missing values: {len(missing_columns)}\")\n",
    "        print(missing_columns.head(10))\n",
    "    else:\n",
    "        print(\"‚úÖ No missing values found!\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beef448",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_target_variable(data, target_column='readmission_risk'):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of the target variable\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input data\n",
    "        target_column (str): Name of the target column\n",
    "    \"\"\"\n",
    "    if target_column not in data.columns:\n",
    "        print(f\"‚ùå Target column '{target_column}' not found in data\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüéØ Target Variable Analysis: {target_column}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Distribution\n",
    "    target_distribution = data[target_column].value_counts()\n",
    "    print(\"Distribution:\")\n",
    "    print(target_distribution)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    target_distribution.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "    plt.title('Readmission Risk Distribution')\n",
    "    plt.xlabel('Readmission Risk')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(target_distribution.values, labels=target_distribution.index, \n",
    "            autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])\n",
    "    plt.title('Readmission Risk Proportion')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Class imbalance check\n",
    "    imbalance_ratio = target_distribution.min() / target_distribution.max()\n",
    "    print(f\"\\n‚öñÔ∏è Class Imbalance Ratio: {imbalance_ratio:.3f}\")\n",
    "    if imbalance_ratio < 0.5:\n",
    "        print(\"‚ö†Ô∏è Significant class imbalance detected - consider resampling techniques\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5aa2f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_numerical_features(data, numerical_columns):\n",
    "    \"\"\"\n",
    "    Analyze numerical features with statistics and visualizations\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input data\n",
    "        numerical_columns (list): List of numerical column names\n",
    "    \"\"\"\n",
    "    print(f\"\\nüî¢ Numerical Features Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if not numerical_columns:\n",
    "        print(\"‚ùå No numerical columns provided\")\n",
    "        return\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"Descriptive Statistics:\")\n",
    "    print(data[numerical_columns].describe())\n",
    "    \n",
    "    # Visualization\n",
    "    n_cols = min(4, len(numerical_columns))\n",
    "    n_rows = (len(numerical_columns) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "    \n",
    "    for i, col in enumerate(numerical_columns):\n",
    "        if i < len(axes):\n",
    "            data[col].hist(bins=30, ax=axes[i], alpha=0.7, color='skyblue')\n",
    "            axes[i].set_title(f'Distribution of {col}')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(numerical_columns), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation analysis\n",
    "    if len(numerical_columns) > 1:\n",
    "        print(\"\\nüìä Correlation Matrix:\")\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        correlation_matrix = data[numerical_columns].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                   square=True, fmt='.2f')\n",
    "        plt.title('Correlation Matrix of Numerical Features')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d35d19",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_categorical_features(data, categorical_columns, target_column=None):\n",
    "    \"\"\"\n",
    "    Analyze categorical features with counts and relationships\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input data\n",
    "        categorical_columns (list): List of categorical column names\n",
    "        target_column (str): Optional target column for relationship analysis\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìã Categorical Features Analysis\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    if not categorical_columns:\n",
    "        print(\"‚ùå No categorical columns provided\")\n",
    "        return\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col not in data.columns:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nüìà Analysis of '{col}':\")\n",
    "        value_counts = data[col].value_counts()\n",
    "        print(f\"Unique values: {data[col].nunique()}\")\n",
    "        print(\"Top 10 values:\")\n",
    "        print(value_counts.head(10))\n",
    "        \n",
    "        # Visualization\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Value counts plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        value_counts.head(10).plot(kind='bar', color='lightseagreen')\n",
    "        plt.title(f'Top 10 Values in {col}')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Relationship with target (if provided)\n",
    "        if target_column and target_column in data.columns:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            cross_tab = pd.crosstab(data[col], data[target_column], normalize='index')\n",
    "            cross_tab.plot(kind='bar', stacked=True, ax=plt.gca(),\n",
    "                          color=['lightcoral', 'lightgreen'])\n",
    "            plt.title(f'{col} vs {target_column}')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.legend(title=target_column)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25925b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data_quality_report(data):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive data quality report\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Data quality report\n",
    "    \"\"\"\n",
    "    print(\"üìã Generating Comprehensive Data Quality Report\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    quality_report = pd.DataFrame(index=data.columns)\n",
    "    \n",
    "    # Basic metrics\n",
    "    quality_report['Data Type'] = data.dtypes\n",
    "    quality_report['Non-Null Count'] = data.count()\n",
    "    quality_report['Null Count'] = data.isnull().sum()\n",
    "    quality_report['Null Percentage'] = (data.isnull().sum() / len(data)) * 100\n",
    "    quality_report['Unique Values'] = data.nunique()\n",
    "    quality_report['Duplicate Rows'] = data.duplicated().sum()\n",
    "    \n",
    "    # For numerical columns\n",
    "    numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
    "    for col in numerical_cols:\n",
    "        quality_report.loc[col, 'Mean'] = data[col].mean()\n",
    "        quality_report.loc[col, 'Median'] = data[col].median()\n",
    "        quality_report.loc[col, 'Std Dev'] = data[col].std()\n",
    "        quality_report.loc[col, 'Min'] = data[col].min()\n",
    "        quality_report.loc[col, 'Max'] = data[col].max()\n",
    "    \n",
    "    print(f\"‚úÖ Data Quality Report Generated\")\n",
    "    print(f\"üìä Dataset Shape: {data.shape}\")\n",
    "    print(f\"‚ùì Total Missing Values: {quality_report['Null Count'].sum()}\")\n",
    "    print(f\"üîÑ Duplicate Rows: {quality_report['Duplicate Rows'].max()}\")\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Example usage in the notebook\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    data = load_and_explore_data('../data/sample_data.csv')\n",
    "    \n",
    "    if data is not None:\n",
    "        # Generate quality report\n",
    "        quality_report = generate_data_quality_report(data)\n",
    "        \n",
    "        # Identify numerical and categorical columns\n",
    "        numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "        \n",
    "        print(f\"\\nüî¢ Numerical columns: {len(numerical_cols)}\")\n",
    "        print(f\"üìã Categorical columns: {len(categorical_cols)}\")\n",
    "        \n",
    "        # Analyze target variable\n",
    "        analyze_target_variable(data)\n",
    "        \n",
    "        # Analyze numerical features\n",
    "        if numerical_cols:\n",
    "            analyze_numerical_features(data, numerical_cols)\n",
    "        \n",
    "        # Analyze categorical features\n",
    "        if categorical_cols:\n",
    "            analyze_categorical_features(data, categorical_cols, 'readmission_risk')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
